{"model": [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [-500.0, -500.0, -500.0, -500.0, 0.0, -500.0, -500.0, -500.0, -500.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]], "wall_penalty": -5.0, "action_reward": -5.0, "episode_count": 1000, "total_reward": -1860295.0, "init_epsilon": 0.9, "policy": ["R", "R", "R", "R", "R", "R", "R", "R", "D", "D", "D", "D", "D", "D", "U", "D", "R", "D", "D", "L", "L", "L", "L", "L", "L", "L", "L", "D", "D", "D", "D", "D", "D", "D", "D", "D", "R", "R", "R", "R", "R", "R", "R", "R", "D", "D", "D", "D", "D", "D", "D", "D", "D", "D", "R", "R", "R", "R", "D", "L", "L", "L", "L", "U", "U", "U", "D", "D", "D", "D", "D", "D", "R", "R", "R", "R", "R", "R", "R", "R", "U"], "value_state": [-116.0, -111.0, -106.0, -101.0, -96.0, -91.0, -86.0, -81.0, -76.0, -31.0, -36.0, -41.0, -46.0, -76.0, -66.0, -60.0, -82.0, -71.0, -26.0, -31.0, -36.0, -41.0, -46.0, -51.0, -56.0, -61.0, -66.0, -21.0, -16.0, -11.0, -6.0, -1.0, 4.0, 10.0, 16.0, 22.0, -16.0, -11.0, -6.0, -1.0, 4.0, 10.0, 16.0, 22.0, 28.0, 6.0, 36.0, 46.0, 52.0, 58.0, 52.0, 46.0, 40.0, 34.0, 38.0, 46.0, 52.0, 58.0, 64.0, 58.0, 52.0, 46.0, 40.0, -24.0, 12.0, 46.0, 64.0, 70.0, 76.0, 82.0, 88.0, 94.0, -20.0, 50.0, 64.0, 70.0, 76.0, 82.0, 88.0, 94.0, 0.0], "epsilon": 0.9, "x_goal": 9, "y_goal": 9, "rows_count": 9, "columns_count": 9, "alpha": 0.9, "gamma": 1.0}